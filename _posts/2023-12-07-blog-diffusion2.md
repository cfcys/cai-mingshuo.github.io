---
title: 'Diffusion入门知识2'
date: 2023-12-07
permalink: /posts/2024/01/blog-diffusion2/
star: superior
tags:
  - 扩散模型
  - VAE
---

这篇博客介绍了我在入门diffusion时入门进一步学到的一些知识。

## 回顾
在入门知识1中，我们主要是了解到VAE的损失函数的简洁形式为

$$
loss=MSE(X,X^{\prime})+KL(N(\mu_{1}, \sigma_{1}^{2}), N(0,1)) 
$$

其中的$MSE(X,X^{\prime})$是就是解码器解码得到的向量和输入向量之间的差距，或者说是重构的损失（reconstruct loss），$KL(N(\mu_{1}, \sigma_{1}^{2}), N(0,1))$则是为了使得编码器生成的因变量更贴近于正态分布。

* reconstruct loss计算的是解码器解码得到的向量和输入向量之间的MSE loss，这一项比较好理解，就是反映出vae生成的结果和输入之间的差异，对应的目标是使vae生成的结果和输入尽可能相似，具体的原理基本类似于最小二乘拟合的原理来衡量误差

* kl散度正则项相较于MES loss理解起来不是。比较正式的说法是使得编码器生成的隐变量尽可能符合标准正态分布。这种说法相当的拗口，常让人不明所以，比如为什么要使用这两个公示。 很直接的一种方法是让我们看看如果我们把reconstruct loss去掉，单单留下kl loss项会导致vae的编码空间变成什么样。这是我在网上找到的一张图片，中间显示的就是只采用kl散度训练后隐空间中的隐变量的分布。所有的输入向量均会被无差别地编码成标准正态分布。

![各种损失的效果](image.png)

> 直观上看来这个kl正则项的作用是使得编码器生成的隐变量符合标准正态分布。那么事实上如何呢？事实上也确实就是使得编码结果接近标准正态分布，只不过由于reconstruct loss的共同作用结果不会是标准正态分布，否则也就编码不出信息了。接下来就是为什么kl项能够使得编码结果符合标准正态分布呢，这就涉及到对kl loss项的公式分析了。

## 什么是ELBO






## cVAE



## 参考资料

https://zhuanlan.zhihu.com/p/578619659